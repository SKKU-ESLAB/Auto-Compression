// Copyright 2019 Google LLC
//
// This source code is licensed under the BSD-style license found in the
// LICENSE file in the root directory of this source tree.

$assert MR % 4 == 0
$assert NR in [1, 2, 4]
$ABC = "0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz01"
$VMULADD_F32 = "vfma_f32" if FMA else "vmla_f32"
$VMULADDQ_F32 = "vfmaq_f32" if FMA else "vmlaq_f32"
$VMULADD_LANE_F32 = "vfma_lane_f32" if FMA else "vmla_lane_f32"
$VMULADDQ_LANE_F32 = "vfmaq_lane_f32" if FMA else "vmlaq_lane_f32"
#include <assert.h>

#include <arm_neon.h>

#include <xnnpack/spmm.h>


void xnn_f32_spmm_minmax_ukernel_${MR}x${NR}__${"neonfma" if FMA else "neon"}_unaligned(
    size_t mc,
    size_t nc,
    const float*restrict input,
    const float*restrict weights,
    const int32_t*restrict widx_dmap,
    const uint32_t*restrict nidx_nnzmap,
    float*restrict output,
    size_t output_stride,
    const union xnn_f32_minmax_params params[restrict XNN_MIN_ELEMENTS(1)])
{
  assert(mc != 0);
  assert(mc % sizeof(float) == 0);
  assert(nc != 0);

  const float32x4_t vmin = vld1q_dup_f32(&params->scalar.min);
  const float32x4_t vmax = vld1q_dup_f32(&params->scalar.max);
  size_t output_decrement = output_stride * nc - ${MR} * sizeof(float);
  while XNN_LIKELY(mc >= ${MR} * sizeof(float)) {
    const float*restrict w = weights;
    const int32_t* dmap = widx_dmap;
    const uint32_t* nnzmap = nidx_nnzmap;
    size_t n = nc - 1;

    // For the first blocked row
    $for N in range(0, NR, 1):
      $if N == 0:
        $for M in range(0, MR, 4):
          float32x4_t vacc${ABC[M:M+4]}n${N};
      $else: 
        float32x4_t vacc${ABC[0:4]}n${N} = vld1q_dup_f32(w); w += 1;
        $for M in range(4, MR, 4):
          float32x4_t vacc${ABC[M:M+4]}n${N} = vacc${ABC[0:4]}n${N};

    while (n != 0) {
      uint32_t nnz = *nnzmap++;

      // Temporary output pipelining
      $for N in range(0, NR, 1):
        $if N < NR-1:
          $for M in range(0, MR, 4):
            vacc${ABC[M:M+4]}n${N} = vacc${ABC[M:M+4]}n${N+1};
        $else:
          vacc${ABC[0:4]}n${N} = vld1q_dup_f32(w); w += 1;
          $for M in range(4, MR, 4):
            vacc${ABC[M:M+4]}n${N} = vacc${ABC[0:4]}n${N};
      if XNN_LIKELY(nnz != 0) {
        do {
          const intptr_t diff = *dmap++;
          const float32x4_t vi${ABC[0:4]} = vld1q_f32(input);
          $for M in range(4, MR, 4):
            const float32x4_t vi${ABC[M:M+4]} = vld1q_f32(input + ${M});
          input = (const float*restrict) ((uintptr_t) input + (uintptr_t) diff);
          $for M in range(0, MR, 16):
            __builtin_prefetch(input + ${M+16});
          $if NR == 1:
            const float32x4_t vw = vld1q_dup_f32(w); w += 1;
          $elif NR == 2:
            const float32x2_t vw = vld1_f32(w); w += 2;
          $elif NR == 4:
            $if FMA == 1:
              const float32x4_t vw = vld1q_f32(w); w += 4;
            $else:
              const float32x2_t vw01 = vld1_f32(w); w += 2;
              const float32x2_t vw23 = vld1_f32(w); w += 2;
          __builtin_prefetch(w + 32);
          $if NR == 1:
            $for M in range(0, MR, 4):
              vacc${ABC[M:M+4]}c0 = ${VMULADDQ_F32}(vacc${ABC[M:M+4]}c0, vi${ABC[M:M+4]}, vw);
          $elif NR == 2:
            $for N in range(NR):
              $for M in range(0, MR, 4):
                vacc${ABC[M:M+4]}n${N} = ${VMULADDQ_LANE_F32}(vacc${ABC[M:M+4]}n${N}, vi${ABC[M:M+4]}, vw, ${N});
          $elif NR == 4:
            $for N in range(NR):
              $for M in range(0, MR, 4):
                $if FMA == 1:
                  vacc${ABC[M:M+4]}n${N} = vfmaq_laneq_f32(vacc${ABC[M:M+4]}n${N}, vi${ABC[M:M+4]}, vw, ${N});
                $else:
                  vacc${ABC[M:M+4]}n${N} = vmlaq_lane_f32(vacc${ABC[M:M+4]}n${N}, vi${ABC[M:M+4]}, vw${ABC[int(N/2)*2:int(N/2)*2+2]}, ${N%2});
        } while (--nnz != 0);
      }
      // Only process for n0
      $for M in range(0, MR, 4):
        float32x4_t vout${ABC[M:M+4]}n0 = vminq_f32(vacc${ABC[M:M+4]}n0, vmax);

      $for M in range(0, MR, 4):
        vout${ABC[M:M+4]}n0 = vmaxq_f32(vout${ABC[M:M+4]}n0, vmin);

      $for M in range(0, MR, 4):
        vst1q_f32(output + ${M}, vout${ABC[M:M+4]}n0);
      output = (float*restrict) ((uintptr_t) output + output_stride);
      n -= 1;
    }
    // For remained blocked rows
    $for N in range(1, NR, 1):
      $for M in range(0, MR, 4):
        float32x4_t vout${ABC[M:M+4]}n${N} = vminq_f32(vacc${ABC[M:M+4]}n${N}, vmax);

    $for N in range(1, NR, 1):
      $for M in range(0, MR, 4):
        vout${ABC[M:M+4]}n${N} = vmaxq_f32(vout${ABC[M:M+4]}n${N}, vmin);

    $for N in range(1, NR, 1):
      $for M in range(0, MR, 4):
        vst1q_f32(output + ${M}, vout${ABC[M:M+4]}n${N});
      output = (float*restrict) ((uintptr_t) output + output_stride);

    output = (float*restrict) ((uintptr_t) output - output_decrement);
    input += ${MR};
    mc -= ${MR} * sizeof(float);
  }
  if XNN_UNLIKELY(mc != 0) {
    $for LOG2M in reversed(range((MR - 1).bit_length())):
      $SUBMR = 1 << LOG2M
      $if SUBMR * 2 >= MR:
        output_decrement += ${MR - SUBMR} * sizeof(float);
      $else:
        output_decrement += ${SUBMR} * sizeof(float);
      if (mc & (${SUBMR} * sizeof(float))) {
        const float*restrict w = weights;
        const int32_t* dmap = widx_dmap;
        const uint32_t* nnzmap = nidx_nnzmap;
        size_t n = nc - 1;

        // For the first blocked row
        $for N in range(0, NR, 1):
          $if N == 0:
            $if SUBMR < 4:
              float32x2_t vacc${ABC[0:SUBMR]}n${N};
            $else:
              float32x4_t vacc${ABC[0:4]}n${N};
            $for M in range(4, SUBMR, 4):
              float32x4_t vacc${ABC[M:M+4]}n${N};
          $else: 
            $if SUBMR < 4:
              float32x2_t vacc${ABC[0:SUBMR]}n${N} = vld1_dup_f32(w); w += 1;
            $else:
              float32x4_t vacc${ABC[0:4]}n${N} = vld1q_dup_f32(w); w += 1;
            $for M in range(4, SUBMR, 4):
              float32x4_t vacc${ABC[M:M+4]}n${N} = vacc${ABC[0:4]}n${N};

        while (n != 0) {
          uint32_t nnz = *nnzmap++;

          // Temporary output pipelining
          $for N in range(0, NR, 1):
            $if N < NR-1:
              $if SUBMR < 4:
                vacc${ABC[0:SUBMR]}n${N} = vacc${ABC[0:SUBMR]}n${N+1};
              $else:
                vacc${ABC[0:4]}n${N} = vacc${ABC[0:4]}n${N+1};
              $for M in range(4, SUBMR, 4):
                vacc${ABC[M:M+4]}n${N} = vacc${ABC[M:M+4]}n${N+1};
            $else:
              $if SUBMR < 4:
                vacc${ABC[0:SUBMR]}n${N} = vld1_dup_f32(w); w += 1;
              $else:
                vacc${ABC[0:4]}n${N} = vld1q_dup_f32(w); w += 1;
              $for M in range(4, SUBMR, 4):
                vacc${ABC[M:M+4]}n${N} = vacc${ABC[0:4]}n${N};

          if XNN_LIKELY(nnz != 0) {
            do {
              const intptr_t diff = *dmap++;
              $if SUBMR == 1:
                const float32x2_t vi${ABC[0]} = vld1_dup_f32(input);
              $elif SUBMR == 2:
                const float32x2_t vi${ABC[0:2]} = vld1_f32(input);
              $else:
                const float32x4_t vi${ABC[0:4]} = vld1q_f32(input);
              $for M in range(4, SUBMR, 4):
                const float32x4_t vi${ABC[M:M+4]} = vld1q_f32(input + ${M});
              input = (const float*restrict) ((uintptr_t) input + (uintptr_t) diff);
              $if NR == 1:
                $if SUBMR < 4:
                  const float32x2_t vw = vld1_dup_f32(w); w += 1;
                $else:
                  const float32x4_t vw = vld1q_dup_f32(w); w += 1;
              $elif NR == 2:
                const float32x2_t vw = vld1_f32(w); w += 2;
              $elif NR == 4:
                $if FMA == 1:
                  const float32x4_t vw = vld1q_f32(w); w += 4;
                $else:
                  const float32x2_t vw01 = vld1_f32(w); w += 2;
                  const float32x2_t vw23 = vld1_f32(w); w += 2;

              $if NR == 1:
                $if SUBMR < 4:
                    vacc${ABC[0:SUBMR]}c0 = ${VMULADDQ_F32}(vacc${ABC[0:SUBMR]}c0, vi${ABC[0:SUBMR]}, vw);
                $else:
                  $for M in range(0, SUBMR, 4):
                    vacc${ABC[M:M+4]}c0 = ${VMULADDQ_F32}(vacc${ABC[M:M+4]}c0, vi${ABC[M:M+4]}, vw);
              $elif NR == 2:
                $for N in range(NR):
                  $if SUBMR < 4:
                    vacc${ABC[0:SUBMR]}n${N} = ${VMULADD_LANE_F32}(vacc${ABC[0:SUBMR]}n${N}, vi${ABC[0:SUBMR]}, vw, ${N});
                  $else:
                    $for M in range(0, SUBMR, 4):
                      vacc${ABC[M:M+4]}n${N} = ${VMULADDQ_LANE_F32}(vacc${ABC[M:M+4]}n${N}, vi${ABC[M:M+4]}, vw, ${N});
              $elif NR == 4:
                $for N in range(NR):
                  $if SUBMR < 4:
                    $if FMA == 1:
                      vacc${ABC[0:SUBMR]}n${N} = vfma_laneq_f32(vacc${ABC[0:SUBMR]}n${N}, vi${ABC[0:SUBMR]}, vw, ${N});
                    $else:
                      vacc${ABC[0:SUBMR]}n${N} = vmla_lane_f32(vacc${ABC[0:SUBMR]}n${N}, vi${ABC[0:SUBMR]}, vw${ABC[int(N/2)*2:int(N/2)*2+2]}, ${N%2});
                  $else:
                    $for M in range(0, SUBMR, 4):
                      $if FMA == 1:
                        vacc${ABC[M:M+4]}n${N} = vfmaq_laneq_f32(vacc${ABC[M:M+4]}n${N}, vi${ABC[M:M+4]}, vw, ${N});
                      $else:
                        vacc${ABC[M:M+4]}n${N} = vmlaq_lane_f32(vacc${ABC[M:M+4]}n${N}, vi${ABC[M:M+4]}, vw${ABC[int(N/2)*2:int(N/2)*2+2]}, ${N%2});
            } while (--nnz != 0);
          }
          // Only process for n0
          $if SUBMR < 4:
            float32x2_t vout${ABC[0:SUBMR]}n0 = vmin_f32(vacc${ABC[0:SUBMR]}n0, vget_low_f32(vmax));
          $else:
            $for M in range(0, SUBMR, 4):
              float32x4_t vout${ABC[M:M+4]}n0 = vminq_f32(vacc${ABC[M:M+4]}n0, vmax);

          $if SUBMR < 4:
            vout${ABC[0:SUBMR]}n0 = vmax_f32(vout${ABC[0:SUBMR]}n0, vget_low_f32(vmin));
          $else:
            $for M in range(0, SUBMR, 4):
              vout${ABC[M:M+4]}n0 = vmaxq_f32(vout${ABC[M:M+4]}n0, vmin);

          $if SUBMR == 1:
            vst1_lane_f32(output + ${M}, vout${ABC[0:SUBMR]}n0, 0);
          $elif SUBMR == 2:
            vst1_f32(output + ${M}, vout${ABC[0:SUBMR]}n0);
          $else:
            $for M in range(0, SUBMR, 4):
              vst1q_f32(output + ${M}, vout${ABC[M:M+4]}n0);
          output = (float*restrict) ((uintptr_t) output + output_stride);
          n -= 1;
        }
        // For remained blocked rows
        $for N in range(1, NR, 1):
          $if SUBMR < 4:
            float32x2_t vout${ABC[0:SUBMR]}n${N} = vmin_f32(vacc${ABC[0:SUBMR]}n${N}, vget_low_f32(vmax));
          $else:
            $for M in range(0, SUBMR, 4):
              float32x4_t vout${ABC[M:M+4]}n${N} = vminq_f32(vacc${ABC[M:M+4]}n${N}, vmax);

        $for N in range(1, NR, 1):
          $if SUBMR < 4:
            vout${ABC[0:SUBMR]}n${N} = vmax_f32(vout${ABC[0:SUBMR]}n${N}, vget_low_f32(vmin));
          $else:
            $for M in range(0, SUBMR, 4):
              vout${ABC[M:M+4]}n${N} = vmaxq_f32(vout${ABC[M:M+4]}n${N}, vmin);

        $for N in range(1, NR):
          $if SUBMR == 1:
            vst1_lane_f32(output + ${M}, vout${ABC[0:SUBMR]}n${N}, 0);
          $elif SUBMR == 2:
            vst1_f32(output + ${M}, vout${ABC[0:SUBMR]}n${N});
          $else:
            $for M in range(0, SUBMR, 4):
              vst1q_f32(output + ${M}, vout${ABC[M:M+4]}n${N});
          output = (float*restrict) ((uintptr_t) output + output_stride);

        output = (float*restrict) ((uintptr_t) output - output_decrement);
        input += ${SUBMR};
      }
    }
}
